{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: overwriting (reusing) task id=bdec272de2e4490699a99a0378e4d0f8\n",
      "2024-04-15 03:33:31,112 - clearml.Repository Detection - WARNING - Could not read Jupyter Notebook: No module named 'nbconvert'\n",
      "2024-04-15 03:33:31,222 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/9670131bfe154f11b1f35546a11e4f69/experiments/bdec272de2e4490699a99a0378e4d0f8/output/log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 898/898 [01:18<00:00, 11.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/e/WORK_DL/VisionLab/src\")\n",
    "\n",
    "#Import library\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from clearml import Task, Logger\n",
    "import tqdm\n",
    "\n",
    "from utils.count_ced_for_points import val_ced_calculate\n",
    "\n",
    "task = Task.init(\n",
    "    project_name='FaceKeypointDetection',\n",
    "    task_name=\"dlib test\",\n",
    "    tags=[\"dlib\", \"test\"]\n",
    ")\n",
    "logger = Logger.current_logger()\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread(\"/mnt/e/WORK_DL/datasets/landmarks_task/300W/test/261068_2.jpg\")\n",
    "\n",
    "paths = glob.glob(\"/mnt/e/WORK_DL/datasets/landmarks_task/Menpo/test/*.[jp][pn]g\")\n",
    "\n",
    "# Call face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "#Load the model of facial key points\n",
    "predictor = dlib.shape_predictor(\"/mnt/e/WORK_DL/VisionLab/shape_predictor_68_face_landmarks.dat\") # \"shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "gt_points = {}\n",
    "predicted_points = {\"dlib_test\": {}}\n",
    "\n",
    "for p in tqdm.tqdm(paths, ncols=150):\n",
    "    markup = np.loadtxt(p.replace(\"png\", \"pts\").replace(\"jpg\", \"pts\"), comments=(\"version:\", \"n_points:\", \"{\", \"}\"))\n",
    "    flg = markup.shape[0] == 68\n",
    "    if not flg:\n",
    "        continue\n",
    "\n",
    "    # Read an image\n",
    "    image = cv2.imread(p)\n",
    "    # Grayscale conversion\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    # Face Detection\n",
    "    faces = detector(gray,1)\n",
    "    # Loop through each face and draw the face rectangle and key points\n",
    "    for i, face in enumerate(faces): #(x,y,w,h)\n",
    "\n",
    "\n",
    "        # Draw a rectangular box\n",
    "        # cv2.rectangle(image,(face.left(),face.top()),(face.right(),face.bottom()),(255,0,0),2)\n",
    "        # Predict key points\n",
    "        shape = predictor(image,face)\n",
    "        # Get the coordinates of key points\n",
    "\n",
    "        eyes_idx=[36,39,42,45]\n",
    "        xmin, ymin, xmax, ymax = face.left(),face.top(),face.right(),face.bottom()\n",
    "        flg2 = False\n",
    "        if all(\n",
    "            [markup[i][0] > xmin for i in eyes_idx] +\n",
    "            [markup[i][1] > ymin for i in eyes_idx] +\n",
    "            [markup[i][0] < xmax for i in eyes_idx] +\n",
    "            [markup[i][1] < ymax for i in eyes_idx]\n",
    "        ):\n",
    "            basename = os.path.basename(p)\n",
    "            predicted_points[\"dlib_test\"][basename] = []\n",
    "\n",
    "            markup = np.loadtxt(p.replace(\"png\", \"pts\").replace(\"jpg\", \"pts\"), comments=(\"version:\", \"n_points:\", \"{\", \"}\"))\n",
    "            gt_points[basename] = (markup[:, 0], markup[:, 1])\n",
    "            # print('created')\n",
    "            for pt in shape.parts():\n",
    "                # Get the horizontal and vertical coordinates\n",
    "                pt_position=[pt.x,pt.y]\n",
    "                # Display/draw key points\n",
    "                # cv2.circle(image,pt_position,3,(0,0,255),-1)\n",
    "                predicted_points[\"dlib_test\"][basename].append(pt_position)\n",
    "            flg2 = True\n",
    "\n",
    "            predicted_points[\"dlib_test\"][basename] = np.asarray(predicted_points[\"dlib_test\"][basename])\n",
    "            # print( predicted_points[\"dlib_test\"][basename].shape,len(shape.parts()), flg2)\n",
    "            predicted_points[\"dlib_test\"][basename] = (predicted_points[\"dlib_test\"][basename][:, 0], predicted_points[\"dlib_test\"][basename][:, 1])\n",
    "            break\n",
    "\n",
    "fig = val_ced_calculate(\n",
    "    predicted_points=predicted_points,\n",
    "    gt_points=gt_points,\n",
    "    output_path=\"/mnt/e/WORK_DL/VisionLab/src/tasks_info/dlib_test\",\n",
    "    normalization_type=\"bbox\",\n",
    "    # left_eye_idx=\"36,39\",\n",
    "    # right_eye_idx=\"42,45\",\n",
    "    epoch=-1\n",
    ")\n",
    "logger.report_matplotlib_figure(\n",
    "    title=f\"Test dlib\",\n",
    "    series=f\"CED@0.08\",\n",
    "    iteration=0,\n",
    "    figure=fig,\n",
    "    report_interactive=False,\n",
    ")\n",
    "\n",
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
